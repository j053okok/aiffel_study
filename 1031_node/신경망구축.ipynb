{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-30T19:14:51.423396100Z",
     "start_time": "2023-10-30T19:14:49.395828300Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 훈련용 디바이스 가져오기"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "28bb4b6e65de4d44"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# 사용 가능한 경우 GPU 또는 MPS와 같은 하드웨어 가속기에서 모델을 훈련\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T19:15:06.970640Z",
     "start_time": "2023-10-30T19:15:06.953633800Z"
    }
   },
   "id": "5862674c8baed87c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 클래스 정의"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5d8b03fe64378d64"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# 파이토치에서 신경망 모듈 가져오기\n",
    "import torch.nn as nn\n",
    "\n",
    "# 파이토치에서 모든 신경망 모듈의 베이스 클래스인 nn.Module을 상속하는 NeuralNetwork 클래스를 정의합니다.\n",
    "class NeuralNetwork(nn.Module):\n",
    "    # 생성자 메서드로 NeuralNetwork 객체를 초기화합니다.\n",
    "    def __init__(self):\n",
    "        # 슈퍼클래스의 생성자 호출 (nn.Module)\n",
    "        super().__init__()\n",
    "        \n",
    "        # 입력 텐서를 평탄화할 레이어 정의하기\n",
    "        # 입력 텐서가 다차원 텐서(예: 이미지)인 경우, 이 레이어는 이를 1차원 텐서로 평탄화합니다.\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        # 레이어의 순차적 컨테이너 정의하기\n",
    "        # 레이어는 정의된 순서대로 적용됩니다.\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),  # First linear layer with input size 28*28 and output size 512\n",
    "            nn.ReLU(),             # ReLU activation function applied element-wise\n",
    "            nn.Linear(512, 512),   # Second linear layer with input size 512 and output size 512\n",
    "            nn.ReLU(),             # ReLU activation function applied element-wise\n",
    "            nn.Linear(512, 10),    # Third linear layer with input size 512 and output size 10\n",
    "        )\n",
    "\n",
    "    # 신경망의 포워드 전달을 정의하는 포워드 메서드\n",
    "    def forward(self, x):\n",
    "        # 입력 텐서 평탄화\n",
    "        x = self.flatten(x)\n",
    "        \n",
    "        # 평탄화된 텐서에 순차적인 레이어 컨테이너 적용하기\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        \n",
    "        # 출력 텐서 반환\n",
    "        return logits"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T19:15:45.531440300Z",
     "start_time": "2023-10-30T19:15:45.512606400Z"
    }
   },
   "id": "c15bebcf78eb4bfb"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 신경망의 인스턴스를 생성하여 device를 지정하여 구조를 출력합니다.\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T19:17:26.050831200Z",
     "start_time": "2023-10-30T19:17:26.033781Z"
    }
   },
   "id": "419ab2c9931fb074"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: tensor([2])\n"
     ]
    }
   ],
   "source": [
    "# 28x28 단일 이미지를 나타내는 크기 (1, 28, 28)의 랜덤 텐서를 생성합니다.\n",
    "X = torch.rand(1, 28, 28, device=device)\n",
    "\n",
    "# 입력 텐서를 신경망 모델에 전달하여 logits을 얻습니다.\n",
    "# 'model' 오브젝트는 정의되어 로드된 신경망 클래스의 인스턴스여야 합니다.\n",
    "logits = model(X)\n",
    "\n",
    "# 소프트맥스 함수를 적용하여 logits을 확률로 변환합니다.\n",
    "# 'dim=1' 인수는 1차원(열)을 따라 Softmax 함수를 적용합니다.\n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "\n",
    "# 1차원을 따라 pred_probab에서 최대값의 인덱스 찾기\n",
    "# y_pred에 할당된 인덱스는 예측된 클래스에 해당합니다.\n",
    "y_pred = pred_probab.argmax(1)\n",
    "\n",
    "# 예상 클래스 인쇄\n",
    "print(f\"Predicted class: {y_pred}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T19:18:39.119548800Z",
     "start_time": "2023-10-30T19:18:39.099600100Z"
    }
   },
   "id": "5a3d3e60dbafbead"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 모델 레이어\n",
    "* FashionMNIST 모델의 레이어를 세분화 \n",
    "* 28x28 크기의 이미지 3개로 구성된 샘플 미니배치를 가져옴"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b0689817eaa432dd"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "input_image = torch.rand(3,28,28)\n",
    "print(input_image.size())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T19:27:55.402602700Z",
     "start_time": "2023-10-30T19:27:55.388260500Z"
    }
   },
   "id": "950f2e516e1e7968"
  },
  {
   "cell_type": "markdown",
   "source": [
    "####  nn.Flatten\n",
    "* 각 2D 28x28 이미지를 784 픽셀 값의 연속 배열로 변환하기 위해 nn.Flatten 레이어를 초기화"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8de91cf29c16fe91"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 784])\n"
     ]
    }
   ],
   "source": [
    "flatten = nn.Flatten()\n",
    "flat_image = flatten(input_image)\n",
    "print(flat_image.size())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T19:29:14.586361500Z",
     "start_time": "2023-10-30T19:29:14.579365500Z"
    }
   },
   "id": "7667f8ca4de01a5b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "####  nn.Linear\n",
    "* 저장된 가중치와 바이어스를 사용하여 입력에 선형 변환을 적용하는 모듈"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c4ff6c2fe71dd41a"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 20])\n"
     ]
    }
   ],
   "source": [
    "layer1 = nn.Linear(in_features=28*28, out_features=20)\n",
    "hidden1 = layer1(flat_image)\n",
    "print(hidden1.size())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T19:29:40.318835100Z",
     "start_time": "2023-10-30T19:29:40.308867400Z"
    }
   },
   "id": "68d3bf7a532e844d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### nn.ReLU\n",
    "* 비선형 활성화 함수는 모델의 입력과 출력 사이에 복잡한 매핑을 생성하는 것\n",
    "*  비선형 활성화함수는 선형 변환 후에 적용되어 비선형성을 도입함으로써 신경망이 다양한 현상을 학습할 수 있도록 도와줍니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "76241c0c4b7dca39"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before ReLU: tensor([[ 0.4743, -0.0690,  0.3589,  0.4472, -0.1861,  0.1954, -0.0496, -0.3752,\n",
      "          0.3133,  0.1363,  0.0435,  0.1738, -0.1798,  0.2668, -0.4744,  0.5998,\n",
      "          0.0663, -0.5331,  0.3837,  0.5801],\n",
      "        [ 0.7383, -0.2533,  0.2000,  0.2397, -0.0026,  0.1583,  0.2527, -0.1919,\n",
      "          0.4965, -0.2452, -0.3168,  0.1904, -0.3446,  0.2073, -0.1664,  0.4459,\n",
      "         -0.1215, -0.2900,  0.3893,  0.4784],\n",
      "        [ 0.6156, -0.3214, -0.1527,  0.3308, -0.2316,  0.2332, -0.0663, -0.2778,\n",
      "          0.2999, -0.0057, -0.1131,  0.0179,  0.0189,  0.2025, -0.3720,  0.2651,\n",
      "          0.0083, -0.2604,  0.4799,  0.4392]], grad_fn=<AddmmBackward0>)\n",
      "\n",
      "\n",
      "After ReLU: tensor([[0.4743, 0.0000, 0.3589, 0.4472, 0.0000, 0.1954, 0.0000, 0.0000, 0.3133,\n",
      "         0.1363, 0.0435, 0.1738, 0.0000, 0.2668, 0.0000, 0.5998, 0.0663, 0.0000,\n",
      "         0.3837, 0.5801],\n",
      "        [0.7383, 0.0000, 0.2000, 0.2397, 0.0000, 0.1583, 0.2527, 0.0000, 0.4965,\n",
      "         0.0000, 0.0000, 0.1904, 0.0000, 0.2073, 0.0000, 0.4459, 0.0000, 0.0000,\n",
      "         0.3893, 0.4784],\n",
      "        [0.6156, 0.0000, 0.0000, 0.3308, 0.0000, 0.2332, 0.0000, 0.0000, 0.2999,\n",
      "         0.0000, 0.0000, 0.0179, 0.0189, 0.2025, 0.0000, 0.2651, 0.0083, 0.0000,\n",
      "         0.4799, 0.4392]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Before ReLU: {hidden1}\\n\\n\")\n",
    "hidden1 = nn.ReLU()(hidden1)\n",
    "print(f\"After ReLU: {hidden1}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T19:31:26.039022Z",
     "start_time": "2023-10-30T19:31:26.021012700Z"
    }
   },
   "id": "ae6c4eb30e8aae1d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### nn.시퀀셜\n",
    "* nn.Sequential은 모듈의 정렬된 컨테이너\n",
    "*  데이터는 정의된 것과 동일한 순서로 모든 모듈을 통과\n",
    "* 시퀀셜 컨테이너를 사용하여 seq_modules와 같은 빠른 네트워크를 구성할 수 있습니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "25ffca60d75ce06d"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "seq_modules = nn.Sequential(\n",
    "    flatten,\n",
    "    layer1,\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20, 10)\n",
    ")\n",
    "input_image = torch.rand(3,28,28)\n",
    "logits = seq_modules(input_image)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T19:32:05.489964400Z",
     "start_time": "2023-10-30T19:32:05.481431Z"
    }
   },
   "id": "b52c5ce413960f00"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### nn.Softmax\n",
    "* 각 클래스에 대한 모델의 예측 확률을 나타내는 [0, 1] 값으로 스케일링\n",
    "* dim 파라미터는 값이 1로 합산되어야 하는 차원을 나타냅니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b590ee41aeba23fe"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "pred_probab = softmax(logits)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T19:33:36.963068400Z",
     "start_time": "2023-10-30T19:33:36.955562Z"
    }
   },
   "id": "b9bf8c29fce2b945"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 모델 파라미터\n",
    "* 레이어는 훈련 중에 최적화된 가중치와 편향이 연관되어 있습니다.\n",
    "* nn.Module을 서브클래싱하면 모델 오브젝트 내부에 정의된 모든 필드를 자동으로 추적\n",
    "* 모델의 parameters() 또는 named_parameters() 메서드를 사용하여 모든 파라미터에 액세스할 수 있습니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1c4995977168fc9c"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure: NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "\n",
      "Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values : tensor([[ 0.0046, -0.0135, -0.0105,  ..., -0.0337,  0.0036, -0.0215],\n",
      "        [ 0.0048,  0.0033,  0.0043,  ..., -0.0307,  0.0083,  0.0193]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values : tensor([-0.0106, -0.0055], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values : tensor([[ 0.0257, -0.0071, -0.0006,  ...,  0.0047, -0.0424, -0.0393],\n",
      "        [-0.0225, -0.0185,  0.0070,  ...,  0.0263, -0.0343, -0.0136]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values : tensor([0.0025, 0.0241], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values : tensor([[ 0.0009,  0.0084, -0.0433,  ..., -0.0089,  0.0432,  0.0435],\n",
      "        [-0.0433,  0.0405, -0.0142,  ..., -0.0047, -0.0173,  0.0285]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.4.bias | Size: torch.Size([10]) | Values : tensor([0.0115, 0.0297], grad_fn=<SliceBackward0>) \n"
     ]
    }
   ],
   "source": [
    "print(f\"Model structure: {model}\\n\\n\")\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T19:34:32.827495300Z",
     "start_time": "2023-10-30T19:34:32.818607400Z"
    }
   },
   "id": "28168b298484589c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512), \n",
    "            nn.ReLU(),            \n",
    "            nn.Linear(512, 512),   \n",
    "            nn.ReLU(),             \n",
    "            nn.Linear(512, 10),    \n",
    "        )"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "29f5d9ae7cc8a8cc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
