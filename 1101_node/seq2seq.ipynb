{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "* NLP 모델링 작업을 수행하기 위해 데이터를 전처리하는 클래스와 함수를 직접 작성하며 프랑스어를 영어로 번역하는 신경망을 학습"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d5bc6ba08938ba22"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 준비하기"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c8efa1c223504a17"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-31T18:55:37.664797700Z",
     "start_time": "2023-10-31T18:55:36.064219Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 데이터 파일 로드\n",
    "* 이 번역기 프로젝트의 데이터셋은 수천 개의 영어-프랑스어 번역 쌍으로 이루어진 데이터셋"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "53c8a5eabf6174d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "* SOS_token: “Start Of Sentence\" 토큰의 약자입니다. 시퀀스의 시작을 나타내는 데 자주 사용됩니다. 기계 번역이나 대화 시스템의 문장과 같은 시퀀스를 처리할 때 모델에 시퀀스의 시작을 나타내는 토큰이 필요할 수 있으며, SOS_token이 이러한 용도로 사용됩니다.\n",
    "\n",
    "* EOS_token: “End Of Sentence\" 토큰을 의미합니다. 시퀀스의 끝을 나타내는 데 사용됩니다. 시작을 나타내는 토큰이 필요한 것처럼, 특히 출력 시퀀스의 길이가 달라질 수 있는 작업에서는 시퀀스의 끝을 나타내는 토큰도 필요합니다.\n",
    "\n",
    "* 이러한 토큰은 다양한 길이의 시퀀스를 처리할 때 순환 신경망(RNN)과 트랜스포머 모델에 특히 유용합니다. 모델이 시퀀스의 시작과 끝을 인식하는 데 도움이 되며, 이는 기계 번역, 텍스트 요약 등과 같은 작업에 매우 중요할 수 있습니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f9a150b88f612672"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# SOS, EOS 토큰 정의\n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        \"\"\"\n",
    "        어휘를 추적하기 위해 Lang 오브젝트를 초기화\n",
    "        \n",
    "        인자:\n",
    "        name (str): 언어명\n",
    "        \n",
    "        속성:\n",
    "        name (str): 언어명\n",
    "        word2index (dict): 단어를 해당 인덱스로의 매핑\n",
    "        word2count (dict): 단어를 해당 단어의 사용 빈도로 매핑\n",
    "        index2word (dict): 인덱스에서 단어로의 매핑. SOS 및 EOS에 대한 매핑으로 초기화\n",
    "        n_words (int): SOS 및 EOS를 포함한 어휘의 총 단어 개수\n",
    "        \"\"\"\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        \"\"\"\n",
    "        문장의 모든 단어를 어휘에 추가합니다.\n",
    "        \n",
    "        인자:\n",
    "        sentence (str): 단어가 공백으로 구분된 문장\n",
    "        \"\"\"\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        \"\"\"\n",
    "        어휘에 단어를 추가\n",
    "        \n",
    "        인자:\n",
    "        word (str): 어휘에 추가할 단어\n",
    "        \"\"\"\n",
    "        if word not in self.word2index:\n",
    "            # 단어가 어휘에 없는 경우 사용 가능한 다음 인덱스로 추가\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            # 단어가 이미 어휘에 있는 경우 개수를 늘립니다.\n",
    "            self.word2count[word] += 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T19:18:21.665176300Z",
     "start_time": "2023-10-31T19:18:21.641770200Z"
    }
   },
   "id": "5c85b0e29e999f3c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "* 파일은 모두 유니코드로 되어 있으므로 간소화하기 위해 유니코드 문자를 ASCII로 바꾸고, 모든 문자를 소문자로 만들고, 구두점을 대부분 잘라냅니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1764e423114e53dc"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# 소문자, 자르기(trim) 및 문자가 아닌 문자 제거\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip()) # 소문자로 변환\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s) \n",
    "    s = re.sub(r\"[^a-zA-Z!?]+\", r\" \", s)\n",
    "    return s.strip()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T19:19:58.467093Z",
     "start_time": "2023-10-31T19:19:58.461092200Z"
    }
   },
   "id": "f79a2635861126d9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "* 데이터 파일을 읽기 위해 파일을 줄(line)로 분할하고 다시 줄을 쌍으로 분할\n",
    "* 파일은 모두 영어 → 기타 언어이므로 기타 언어 → 영어에서 번역하려면 쌍을 반대로 바꾸기 위해 역방향 플래그를 추가"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d41b2474daa3389c"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # 파일을 읽고 여러 줄로 분할\n",
    "    lines = open(os.getenv(\"HOME\") + '/aiffel/pytorch_nlp/data/data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "\n",
    "    # 모든 줄을 쌍으로 분할하고 정규화\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "    # 리버스(reverse) 쌍, Lang 인스턴스 만들기\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T19:20:31.092282200Z",
     "start_time": "2023-10-31T19:20:31.083645700Z"
    }
   },
   "id": "85fcf4c81b6f3b1e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "* 데이터셋을 비교적 짧고 간단한 문장으로만 정리\n",
    "* 여기서 최대 길이는 10단어(문장 부호 포함)\n",
    "* '나는' 또는 '그는' 등의 형태로 번역되는 문장으로 필터링 (앞서 교체된 작은 따옴표(')를 고려)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "703cb8c25ed9037c"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s \",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "        p[1].startswith(eng_prefixes)\n",
    "\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T19:21:50.552753400Z",
     "start_time": "2023-10-31T19:21:50.544816100Z"
    }
   },
   "id": "f2c9f3e1e79958b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 데이터 준비의 전체 프로세스\n",
    "* 텍스트 파일을 읽고 줄로 분할하고, 줄을 쌍으로 분할\n",
    "* 텍스트 정규화, 길이 및 내용별로 필터링\n",
    "* 쌍으로 된 문장에서 단어 목록 만들기"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3216469c8bb81e0c"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'NoneType' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 47\u001B[0m\n\u001B[0;32m     44\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m input_lang, output_lang, pairs\n\u001B[0;32m     46\u001B[0m \u001B[38;5;66;03m# 데이터를 준비하고 임의의 문장 쌍을 출력\u001B[39;00m\n\u001B[1;32m---> 47\u001B[0m input_lang, output_lang, pairs \u001B[38;5;241m=\u001B[39m \u001B[43mprepareData\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43meng\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mfra\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m     48\u001B[0m \u001B[38;5;28mprint\u001B[39m(random\u001B[38;5;241m.\u001B[39mchoice(pairs))\n",
      "Cell \u001B[1;32mIn[6], line 19\u001B[0m, in \u001B[0;36mprepareData\u001B[1;34m(lang1, lang2, reverse)\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;124;03m문장 쌍을 읽고, 필터링하고, 단어 수를 세어 학습용 데이터를 준비합니다.\u001B[39;00m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;124;03m\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     16\u001B[0m \u001B[38;5;124;03m    - pairs (list of tuples): 문장 쌍의 목록\u001B[39;00m\n\u001B[0;32m     17\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     18\u001B[0m \u001B[38;5;66;03m# 언어 쌍을 읽고 Lang 오브젝트 만들기\u001B[39;00m\n\u001B[1;32m---> 19\u001B[0m input_lang, output_lang, pairs \u001B[38;5;241m=\u001B[39m \u001B[43mreadLangs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlang1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlang2\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreverse\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     21\u001B[0m \u001B[38;5;66;03m# 읽은 문장 쌍의 수 출력\u001B[39;00m\n\u001B[0;32m     22\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRead \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m sentence pairs\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m \u001B[38;5;28mlen\u001B[39m(pairs))\n",
      "Cell \u001B[1;32mIn[4], line 7\u001B[0m, in \u001B[0;36mreadLangs\u001B[1;34m(lang1, lang2, reverse)\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mReading lines...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      6\u001B[0m \u001B[38;5;66;03m# 파일을 읽고 여러 줄로 분할\u001B[39;00m\n\u001B[1;32m----> 7\u001B[0m lines \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetenv\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mHOME\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m/aiffel/pytorch_nlp/data/data/\u001B[39;49m\u001B[38;5;132;43;01m%s\u001B[39;49;00m\u001B[38;5;124;43m-\u001B[39;49m\u001B[38;5;132;43;01m%s\u001B[39;49;00m\u001B[38;5;124;43m.txt\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m%\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mlang1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlang2\u001B[49m\u001B[43m)\u001B[49m, encoding\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39m\\\n\u001B[0;32m      8\u001B[0m     read()\u001B[38;5;241m.\u001B[39mstrip()\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     10\u001B[0m \u001B[38;5;66;03m# 모든 줄을 쌍으로 분할하고 정규화\u001B[39;00m\n\u001B[0;32m     11\u001B[0m pairs \u001B[38;5;241m=\u001B[39m [[normalizeString(s) \u001B[38;5;28;01mfor\u001B[39;00m s \u001B[38;5;129;01min\u001B[39;00m l\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\t\u001B[39;00m\u001B[38;5;124m'\u001B[39m)] \u001B[38;5;28;01mfor\u001B[39;00m l \u001B[38;5;129;01min\u001B[39;00m lines]\n",
      "\u001B[1;31mTypeError\u001B[0m: unsupported operand type(s) for +: 'NoneType' and 'str'"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    \"\"\"\n",
    "    문장 쌍을 읽고, 필터링하고, 단어 수를 세어 학습용 데이터를 준비합니다.\n",
    "    \n",
    "    인자:\n",
    "    lang1 (str): 소스 언어의 이름\n",
    "    lang2 (str): 타겟 언어의 이름\n",
    "    reverse (bool, optional): True이면 소스 언어와 타겟 언어의 순서를 반대로 합니다. 기본값은 False\n",
    "    \n",
    "    리턴:\n",
    "    tuple: 다음을 포함하는 튜플:\n",
    "        - input_lang (Lang): 소스 언어에 대한 Lang 오브젝트\n",
    "        - output_lang (Lang): 타겟 언어에 대한 Lang 오브젝트\n",
    "        - pairs (list of tuples): 문장 쌍의 목록\n",
    "    \"\"\"\n",
    "    # 언어 쌍을 읽고 Lang 오브젝트 만들기\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    \n",
    "    # 읽은 문장 쌍의 수 출력\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    \n",
    "    # 특정 기준(예: 길이)에 따라 문장 쌍을 필터링\n",
    "    pairs = filterPairs(pairs)\n",
    "    \n",
    "    # 필터링 후 문장 쌍의 수를 출력\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    \n",
    "    # 단어 카운트가 시작되었음을 나타내는 메시지를 출력\n",
    "    print(\"Counting words...\")\n",
    "    \n",
    "    # 쌍에서 각 Lang 오브젝트에 문장을 추가\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    \n",
    "    # 각 언어에 대해 계산된 단어 수를 출력\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    \n",
    "    # Lang 오브젝트와 문장 쌍을 리턴\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "# 데이터를 준비하고 임의의 문장 쌍을 출력\n",
    "input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
    "print(random.choice(pairs))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T19:27:22.673741700Z",
     "start_time": "2023-10-31T19:27:22.571992800Z"
    }
   },
   "id": "cd5c098b70adcf9f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Seq2Seq 모델"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a346af89d9da8adc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 인코더\n",
    "* seq2seq 네트워크의 인코더는 입력 문장의 모든 단어에 대해 특정 값을 출력하는 RNN\n",
    "* 인코더는 모든 입력 단어에 대해 벡터와 숨겨진 상태를 출력하고 다음 입력 단어에 숨겨진 상태를 사용\n",
    "* GRU는 LSTM을 개량한 구조로 LSTM에 비해 전체적으로 파라미터가 작고 계산량이 적음"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eb9897d63f329ffa"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout_p=0.1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, input):\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        output, hidden = self.gru(embedded)\n",
    "        return output, hidden"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T19:38:50.123375300Z",
     "start_time": "2023-10-31T19:38:50.115651500Z"
    }
   },
   "id": "de43604fecb0ec8f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 디코더\n",
    "* 디코더는 인코더 출력 벡터를 가져와 번역을 생성하기 위해 단어 시퀀스를 출력하는 또 다른 RNN\n",
    "* 초기 입력 토큰은 문자열 시작 SOS 토큰\n",
    "* 첫 번째 숨겨진 상태는 컨텍스트 벡터(인코더의 마지막 숨겨진 상태)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d5f825e3379e7680"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_outputs = []\n",
    "\n",
    "        for i in range(MAX_LENGTH):\n",
    "            decoder_output, decoder_hidden  = self.forward_step(decoder_input, decoder_hidden)\n",
    "            decoder_outputs.append(decoder_output)\n",
    "\n",
    "            if target_tensor is not None:\n",
    "                # Teacher forcing: 다음 입력으로 타겟을 제공(feed)\n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
    "            else:\n",
    "                # Without teacher forcing: 자체 예측을 다음 입력으로 사용\n",
    "                _, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze(-1).detach()  # 기록(history)에서 입력으로 분리\n",
    "\n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
    "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
    "        return decoder_outputs, decoder_hidden, None # 학습 루프의 일관성을 위해 'None'을 반환\n",
    "\n",
    "    def forward_step(self, input, hidden):\n",
    "        output = self.embedding(input)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.out(output)\n",
    "        return output, hidden"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T19:39:58.368499700Z",
     "start_time": "2023-10-31T19:39:58.347909800Z"
    }
   },
   "id": "d51bfdac1a62815a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 어텐션 디코더\n",
    "* 인코더와 디코더 사이에 컨텍스트 벡터만 전달되는 경우, 단일 벡터가 전체 문장을 인코딩해야 하는 부담을 안게 됨\n",
    "* 어텐션은 디코더 네트워크가 디코더 자체 출력 단계마다 인코더 출력의 다른 부분에 \"집중\"할 수 있도록 함\n",
    "* 어텐션 가중치 세트를 계산 후 여기에 인코더 출력 벡터를 곱하여 가중치 조합을 생성\n",
    "* 결과(코드에서는 attn_applied라고 함)에는 입력 시퀀스의 특정 부분에 대한 정보가 포함되어 있어야 함\n",
    "* 어텐션 가중치 계산은 디코더의 입력과 숨겨진 상태를 입력으로 사용하는 또 다른 피드포워드 레이어 attn으로 수행\n",
    "* 최대 길이의 문장은 모든 어텐션 가중치를 사용하지만, 짧은 문장은 처음 몇 개만 사용"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "77322b12380cffa5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "* 바흐다나우 어텐션을 사용\n",
    "* 바흐다나우(Bahdanau) 어텐션은 시퀀스 간 모델, 특히 신경 기계 번역 작업에서 일반적으로 사용되는 어텐션 메커니즘\n",
    "* 학습된 정렬 모델을 사용하여 인코더와 디코더 숨겨진 상태 간의 어텐션 점수를 계산\n",
    "* 이 모델은 피드포워드 신경망을 사용하여 정렬 점수를 계산"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bf997134434dd5ef"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "class BahdanauAttention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.Wa = nn.Linear(hidden_size, hidden_size)\n",
    "        self.Ua = nn.Linear(hidden_size, hidden_size)\n",
    "        self.Va = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, query, keys):\n",
    "        scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))\n",
    "        scores = scores.squeeze(2).unsqueeze(1)\n",
    "\n",
    "        weights = F.softmax(scores, dim=-1)\n",
    "        context = torch.bmm(weights, keys)\n",
    "\n",
    "        return context, weights\n",
    "\n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.attention = BahdanauAttention(hidden_size)\n",
    "        self.gru = nn.GRU(2 * hidden_size, hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_outputs = []\n",
    "        attentions = []\n",
    "\n",
    "        for i in range(MAX_LENGTH):\n",
    "            decoder_output, decoder_hidden, attn_weights = self.forward_step(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            decoder_outputs.append(decoder_output)\n",
    "            attentions.append(attn_weights)\n",
    "\n",
    "            if target_tensor is not None:\n",
    "                # Teacher forcing: 다음 입력으로 타겟을 공급(feed)\n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
    "            else:\n",
    "                # Without teacher forcing: 자체 예측을 다음 입력으로 사용\n",
    "                _, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze(-1).detach()  # 기록에서 입력으로 분리\n",
    "\n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
    "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
    "        attentions = torch.cat(attentions, dim=1)\n",
    "\n",
    "        return decoder_outputs, decoder_hidden, attentions\n",
    "\n",
    "\n",
    "    def forward_step(self, input, hidden, encoder_outputs):\n",
    "        embedded =  self.dropout(self.embedding(input))\n",
    "\n",
    "        query = hidden.permute(1, 0, 2)\n",
    "        context, attn_weights = self.attention(query, encoder_outputs)\n",
    "        input_gru = torch.cat((embedded, context), dim=2)\n",
    "\n",
    "        output, hidden = self.gru(input_gru, hidden)\n",
    "        output = self.out(output)\n",
    "\n",
    "        return output, hidden, attn_weights"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T19:55:04.410399900Z",
     "start_time": "2023-10-31T19:55:04.370372400Z"
    }
   },
   "id": "573dd8c4ca50d4ad"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 학습 데이터 준비하기\n",
    "* 학습을 위해서는 각 쌍에 대해 입력 텐서(입력 문장에 있는 단어의 인덱스)와 목표 텐서(목표 문장에 있는 단어의 인덱스)가 필요\n",
    "* 이러한 벡터를 생성하는 동안 두 시퀀스 모두에 EOS 토큰을 추가"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d747af431da669df"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(1, -1)\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)\n",
    "\n",
    "def get_dataloader(batch_size):\n",
    "    input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
    "\n",
    "    n = len(pairs)\n",
    "    input_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
    "    target_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
    "\n",
    "    for idx, (inp, tgt) in enumerate(pairs):\n",
    "        inp_ids = indexesFromSentence(input_lang, inp)\n",
    "        tgt_ids = indexesFromSentence(output_lang, tgt)\n",
    "        inp_ids.append(EOS_token)\n",
    "        tgt_ids.append(EOS_token)\n",
    "        input_ids[idx, :len(inp_ids)] = inp_ids\n",
    "        target_ids[idx, :len(tgt_ids)] = tgt_ids\n",
    "\n",
    "    train_data = TensorDataset(torch.LongTensor(input_ids).to(device),\n",
    "                               torch.LongTensor(target_ids).to(device))\n",
    "\n",
    "    train_sampler = RandomSampler(train_data)\n",
    "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "    return input_lang, output_lang, train_dataloader"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T20:02:18.211132100Z",
     "start_time": "2023-10-31T20:02:18.188793800Z"
    }
   },
   "id": "b44548e0b51f033e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 모델 학습\n",
    "* 인코더를 통해 입력 문장을 실행하고 모든 출력값과 최근 은닉 상태(hidden state)를 추적\n",
    "* 디코더에 첫 번째 입력으로 <SOS> 토큰이 주어지고 인코더의 마지막 숨겨진 상태가 첫 번째 숨겨진 상태로 주어짐\n",
    "* Teacher forcing 개념 사용\n",
    "* \"Teacher forcing\"는 디코더의 추측을 다음 입력으로 사용하는 대신 실제 목표 출력을 각 다음 입력으로 사용하는 개념\n",
    "* Teacher forcing을 사용하면 더 빠르게 수렴할 수 있지만, 학습된 네트워크가 잘못 사용되면 불안정성을 보일 수 있음"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8617a38899f9dc1e"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def train_epoch(dataloader, encoder, decoder, encoder_optimizer,\n",
    "          decoder_optimizer, criterion):\n",
    "\n",
    "    total_loss = 0\n",
    "    for data in dataloader:\n",
    "        input_tensor, target_tensor = data\n",
    "\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
    "\n",
    "        loss = criterion(\n",
    "            decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
    "            target_tensor.view(-1)\n",
    "        )\n",
    "        loss.backward()\n",
    "\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(dataloader)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T20:11:22.767849100Z",
     "start_time": "2023-10-31T20:11:22.744914300Z"
    }
   },
   "id": "7c9c1c16995a1e88"
  },
  {
   "cell_type": "markdown",
   "source": [
    "* 현재 시간과 진행률(%)를 기준으로 경과된 시간과 남은 예상 시간을 인쇄하는 헬퍼(helper) 함수"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3f40689724418a86"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T20:12:02.876878800Z",
     "start_time": "2023-10-31T20:12:02.853939900Z"
    }
   },
   "id": "9a74cd5696583e4c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 전체 학습 과정\n",
    "* 타이머 시작\n",
    "* 옵티마이저 및 기준 초기화하기\n",
    "* 학습 쌍 세트 생성\n",
    "* 플로팅(plotting)을 위해 빈(empty) 손실값 배열을 시작\n",
    "* 그런 다음 학습을 여러 번 호출하고 진행 상황(예제의 %, 지금까지의 시간, 예상 시간)과 평균 손실을 가끔씩 출력"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a29d2e82f243cbae"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def train(train_dataloader, encoder, decoder, n_epochs, learning_rate=0.001,\n",
    "               print_every=100, plot_every=100):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # 모든 print_every마다 리셋\n",
    "    plot_loss_total = 0  # 모든 plot_every마다 리셋\n",
    "\n",
    "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if epoch % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, epoch / n_epochs),\n",
    "                                        epoch, epoch / n_epochs * 100, print_loss_avg))\n",
    "\n",
    "        if epoch % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T20:12:36.586976Z",
     "start_time": "2023-10-31T20:12:36.544955800Z"
    }
   },
   "id": "602804c724f4a74"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 결과 플로팅을 이용해 시각화하기\n",
    "* 플로팅은 학습 중에 저장된 손실 값 plot_losses 배열을 사용하여 matplotlib로 수행"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9342994e74d96006"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # 이 로케이터는 일정한 간격으로 틱을 배치\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T20:12:48.802146200Z",
     "start_time": "2023-10-31T20:12:48.166044300Z"
    }
   },
   "id": "3c1d1fe786054119"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 평가\n",
    "* 단어를 예측할 때마다 출력 문자열에 추가\n",
    "*  EOS 토큰을 예측하면 거기서 멈춤\n",
    "* 나중에 표시할 수 있도록 디코더의 주의 출력을 저장"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7a118b6a9bbdd654"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, input_lang, output_lang):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "        decoder_outputs, decoder_hidden, decoder_attn = decoder(encoder_outputs, encoder_hidden)\n",
    "\n",
    "        _, topi = decoder_outputs.topk(1)\n",
    "        decoded_ids = topi.squeeze()\n",
    "\n",
    "        decoded_words = []\n",
    "        for idx in decoded_ids:\n",
    "            if idx.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            decoded_words.append(output_lang.index2word[idx.item()])\n",
    "    return decoded_words, decoder_attn"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T20:14:35.804727100Z",
     "start_time": "2023-10-31T20:14:35.763789200Z"
    }
   },
   "id": "143446d1e806e487"
  },
  {
   "cell_type": "markdown",
   "source": [
    "* 학습 데이터셋에서 임의의 문장을 평가하고 입력값, 타겟값 및 출력값을 출력하여 주관적인 품질 판단을 내릴 수 있음"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ad6503cd1681563b"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, _ = evaluate(encoder, decoder, pair[0], input_lang, output_lang)\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T20:14:49.514052700Z",
     "start_time": "2023-10-31T20:14:49.510055300Z"
    }
   },
   "id": "92b48543505c6bc2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 훈련 및 평가"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "39be8adf0a96faf0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hidden_size = 128\n",
    "batch_size = 32\n",
    "\n",
    "input_lang, output_lang, train_dataloader = get_dataloader(batch_size)\n",
    "\n",
    "encoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "decoder = AttnDecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
    "\n",
    "train(train_dataloader, encoder, decoder, 80, print_every=5, plot_every=5)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "911bd87ba221989"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 드롭아웃 레이어를 평가 모드로 설정\n",
    "encoder.eval()\n",
    "decoder.eval()\n",
    "evaluateRandomly(encoder, decoder)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9914e5ef1c5a00c0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 어텐션 시각화\n",
    "* 어텐션 메커니즘의 유용한 특성은 고도로 해석 가능한 출력"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ffd124b90b2a576a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def showAttention(input_sentence, output_words, attentions):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(attentions.cpu().numpy(), cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # Set up axes\n",
    "    ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
    "                       ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def evaluateAndShowAttention(input_sentence):\n",
    "    output_words, attentions = evaluate(encoder, decoder, input_sentence, input_lang, output_lang)\n",
    "    print('input =', input_sentence)\n",
    "    print('output =', ' '.join(output_words))\n",
    "    showAttention(input_sentence, output_words, attentions[0, :len(output_words), :])\n",
    "\n",
    "\n",
    "evaluateAndShowAttention('il n est pas aussi grand que son pere')\n",
    "\n",
    "evaluateAndShowAttention('je suis trop fatigue pour conduire')\n",
    "\n",
    "evaluateAndShowAttention('je suis desole si c est une question idiote')\n",
    "\n",
    "evaluateAndShowAttention('je suis reellement fiere de vous')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ebcd4763b7f7ae41"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "4ff52ebf0b72c3cb"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "226cc489ab1281"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
