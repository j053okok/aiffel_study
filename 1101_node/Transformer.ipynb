{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### 모델 정의하기\n",
    "* 언어 모델링 작업에서 nn.TransformerEncoder 모델을 학습\n",
    "* 언어 모델링 작업의 경우 현재보다 미래에 위치해 있는 모든 토큰을 마스킹해야 함\n",
    "* 출력 단어에 대한 확률 분포를 생성하기 위해 nn.TransformerEncoder 모델의 출력은 선형 레이어를 통과하여 정규화되지 않은 로짓(logits)을 출력\n",
    "* 나중에 입력이 정규화되지 않은 로짓 값이어야 하는 CrossEntropyLoss를 사용"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4a69546f4e24ad3"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-31T18:16:47.839674700Z",
     "start_time": "2023-10-31T18:16:45.212193600Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "from tempfile import TemporaryDirectory\n",
    "from typing import Tuple\n",
    "\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torch.utils.data import dataset\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, ntoken: int, d_model: int, nhead: int, d_hid: int, nlayers: int, dropout: float = 0.5):\n",
    "        \"\"\"\n",
    "        시퀀스 대 시퀀스 작업을 위한 트랜스포머 모델입니다.\n",
    "\n",
    "        인자:\n",
    "            ntoken(int): 토큰의 개수(어휘의 크기).\n",
    "            d_model (int): 모델의 치수(임베딩 크기).\n",
    "            nhead (int): 어텐션 헤드의 개수.\n",
    "            d_hid (int): Feedforward 네트워크 모델의 차원.\n",
    "            nlayers (int): 트랜스포머 인코더 레이어 수입니다.\n",
    "            dropout(실수, 선택 사항): 드롭아웃 비율. 기본값은 0.5입니다.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "        encoder_layers = TransformerEncoderLayer(d_model, nhead, d_hid, dropout, batch_first=True)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.embedding = nn.Embedding(ntoken, d_model)\n",
    "        self.d_model = d_model\n",
    "        self.linear = nn.Linear(d_model, ntoken)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self) -> None:\n",
    "        \"\"\"\n",
    "        임베딩 및 선형 레이어의 가중치를 초기화합니다.\n",
    "        \"\"\"\n",
    "        initrange = 0.1\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.linear.bias.data.zero_()\n",
    "        self.linear.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src: Tensor, src_mask: Tensor = None) -> Tensor:\n",
    "        \"\"\"\n",
    "        인자:\n",
    "            src: 텐서, 모양 ``[seq_len, batch_size]``\n",
    "            src_mask: 텐서, 모양 ``[seq_len, seq_len]``\n",
    "\n",
    "        출력:\n",
    "            ``[seq_len, batch_size, ntoken]`` 형태의 Tensor를 반환합니다.\n",
    "        \"\"\"\n",
    "        src = self.embedding(src) * math.sqrt(self.d_model)\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src, src_mask)\n",
    "        output = self.linear(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "* PositionalEncoding 모듈은 시퀀스 내 토큰의 상대적 또는 절대적 위치에 대한 정보를 삽입\n",
    "* 위치 인코딩은 임베딩과 동일한 차원을 가지므로 둘을 합산할 수 있음\n",
    "* 주파수가 다른 sine과 cosine 함수를 사용"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2d379545b9e068d0"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"\n",
    "    트랜스포머 모델용 포지셔널 인코딩 클래스입니다.\n",
    "    이 클래스는 시퀀스에서 각 토큰의 위치에 대한 정보를 추가하는 방법을 제공합니다.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
    "        \"\"\"\n",
    "        포지셔널 인코딩 모듈을 초기화합니다.\n",
    "\n",
    "        인자:\n",
    "            d_model (int): 모델의 치수(임베딩 크기).\n",
    "            dropout(float, 선택 사항): 드롭아웃 비율. 기본값은 0.1입니다.\n",
    "            max_len (int, 선택 사항): 시퀀스의 최대 길이. 기본값은 5,000입니다.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        # 위치 [0, max_len]에 대한 텐서를 생성\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        \n",
    "        # 사인(sine) 인코딩을 위한 div_term 계산\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        \n",
    "        # 위치 인코딩 행렬을 0으로 초기화\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        \n",
    "        # 텐서의 짝수 인덱스에 사인(sine) 인코딩 적용; 2i\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        \n",
    "        # 텐서의 홀수 인덱스에 코사인 인코딩 적용; 2i+1\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        \n",
    "        # 모델 파라미터로 간주해서는 안 되는 버퍼로 'pe'를 등록합니다.\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        포지셔널 인코딩 모듈의 forward 전달\n",
    "\n",
    "        인자:\n",
    "            x (Tensor): [seq_len, batch_size, embedding_dim] 구조의 입력 텐서\n",
    "\n",
    "        리턴:\n",
    "            텐서: 입력 텐서에 포지셔널 인코딩이 추가된 출력 텐서\n",
    "        \"\"\"\n",
    "        # 입력 텐서에 포지셔널 인코딩 추가\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        \n",
    "        # 드롭아웃 적용\n",
    "        return self.dropout(x)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T18:22:54.095160Z",
     "start_time": "2023-10-31T18:22:54.077741200Z"
    }
   },
   "id": "bb7384ab96d7c20"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 데이터 로드 및 배치"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "93d6b14891a422a7"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from torchtext.datasets import WikiText2\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "# WikiText-2 학습 데이터셋 불러오기\n",
    "train_iter = WikiText2(split='train')\n",
    "\n",
    "# 텍스트를 토큰으로 변환하는 토크나이저 정의\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "\n",
    "# 학습데이터셋에서 어휘(vocab) 구축\n",
    "vocab = build_vocab_from_iterator(map(tokenizer, train_iter), specials=['<unk>'])\n",
    "vocab.set_default_index(vocab['<unk>'])\n",
    "\n",
    "def data_process(raw_text_iter: dataset.IterableDataset) -> Tensor:\n",
    "    \"\"\"\n",
    "    원시(raw) 텍스트를 플랫(flat) 텐서로 변환합니다.\n",
    "\n",
    "    인자:\n",
    "        raw_text_iter(dataset.IterableDataset): 원시 텍스트의 이터러블 데이터셋입니다.\n",
    "\n",
    "    리턴:\n",
    "        텐서: 토큰 인덱스의 플랫 텐서입니다.\n",
    "    \"\"\"\n",
    "    # 원시 텍스트를 토큰화하고, 토큰을 인덱스로 변환하고, 각 줄에 대한 텐서를 생성합니다.\n",
    "    data = [torch.tensor(vocab(tokenizer(item)), dtype=torch.long) for item in raw_text_iter]\n",
    "    \n",
    "    # 모든 텐서를 연결(Concatenate)하고 빈 텐서는 걸러냅니다.\n",
    "    return torch.cat(tuple(filter(lambda t: t.numel() > 0, data)))\n",
    "\n",
    "# 어휘 구축 중에 학습 이터레이터가 소모되었으므로 다시 생성합니다.\n",
    "train_iter, val_iter, test_iter = WikiText2()\n",
    "\n",
    "# 원시 텍스트 데이터를 텐서로 처리\n",
    "train_data = data_process(train_iter)\n",
    "val_data = data_process(val_iter)\n",
    "test_data = data_process(test_iter)\n",
    "\n",
    "# 사용할 디바이스 정의(사용 가능한 경우 GPU, 그렇지 않은 경우 CPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def batchify(data: Tensor, bsz: int) -> Tensor:\n",
    "    \"\"\"\n",
    "    데이터를 분리된 시퀀스로 나누고, 깔끔하게 맞지 않는 초과 요소를 제거합니다.\n",
    "\n",
    "    인자:\n",
    "        data(텐서): [N] 구조의 텐서입니다.\n",
    "        bsz (int): 배치 크기.\n",
    "\n",
    "    리턴:\n",
    "        텐서: [N // bsz, bsz] 구조의 텐서.\n",
    "    \"\"\"\n",
    "    # 형성할 수 있는 전체 시퀀스의 수를 계산합니다.\n",
    "    seq_len = data.size(0) // bsz\n",
    "    \n",
    "    # 전체 시퀀스에 정확히 맞도록 데이터 다듬기\n",
    "    data = data[:seq_len * bsz]\n",
    "    \n",
    "    # 데이터 구조를 변경하고 지정된 장치로 옮기기\n",
    "    data = data.view(bsz, seq_len).t().contiguous()\n",
    "    return data.to(device)\n",
    "\n",
    "# 학습 및 평가를 위한 배치 크기 정의\n",
    "batch_size = 20\n",
    "eval_batch_size = 10\n",
    "\n",
    "# 데이터 batchify\n",
    "train_data = batchify(train_data, batch_size)  # [seq_len, batch_size] 구조\n",
    "val_data = batchify(val_data, eval_batch_size)\n",
    "test_data = batchify(test_data, eval_batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T18:35:28.526239800Z",
     "start_time": "2023-10-31T18:35:13.095471900Z"
    }
   },
   "id": "1774233c1b9cd924"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 입력 및 타겟 시퀀스를 생성하는 함수\n",
    "* get_batch()는 트랜스포머 모델에 대한 입력-타겟 시퀀스 쌍을 생성\n",
    "* 이 함수는 소스 데이터를 bptt 길이의 말뭉치(chunk)로 세분화"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2b74a301dd37d3e8"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "bptt = 35\n",
    "def get_batch(source: Tensor, i: int) -> Tuple[Tensor, Tensor]:\n",
    "    \"\"\"\n",
    "    인자:\n",
    "        source: Tensor, shape ``[full_seq_len, batch_size]``\n",
    "        i: int\n",
    "\n",
    "    리턴:\n",
    "        tuple (data, target), where data has shape ``[seq_len, batch_size]`` and\n",
    "        target has shape ``[seq_len * batch_size]``\n",
    "    \"\"\"\n",
    "    seq_len = min(bptt, len(source) - 1 - i)\n",
    "    data = source[i:i+seq_len]\n",
    "    target = source[i+1:i+1+seq_len].reshape(-1)\n",
    "    return data, target"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T18:39:53.601945900Z",
     "start_time": "2023-10-31T18:39:53.584856900Z"
    }
   },
   "id": "de952ae4b5d9c633"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 인스턴스 초기 설정하기"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5dc4d6208087b7a3"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "ntokens = len(vocab)  # 단어의 크기\n",
    "emsize = 200  # 임베딩 차원\n",
    "d_hid = 200  # 피드포워드 네트워크 모델의 차원을 \"nn.TransformerEncoder\"로 설정합니다.\n",
    "nlayers = 2  # \"nn.TransformerEncoder\"의 \"nn.TransformerEncoderLayer\" 개수입니다.\n",
    "nhead = 2  # \"nn.MultiheadAttention\"의 헤드 수\n",
    "dropout = 0.2  # 드롭 아웃 확률\n",
    "model = TransformerModel(ntokens, emsize, nhead, d_hid, nlayers, dropout).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T18:40:28.927739700Z",
     "start_time": "2023-10-31T18:40:28.786338100Z"
    }
   },
   "id": "141ad0eceb09e4b4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 모델 실행\n",
    "* SGD(확률적 경사 하강법) 옵티마이저와 함께 CrossEntropyLoss를 사용\n",
    "* 학습율는 처음에 5.0으로 설정되며 StepLR 스케줄을 따름\n",
    "* 학습 중에는 nn.utils.clip_grad_norm_을 사용하여 그래디언트가 폭발하는 것을 방지"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "72729d1f0050d1b2"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 5.0  # 학습률\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n",
    "\n",
    "def train(model: nn.Module) -> None:\n",
    "    model.train()  # 학습모드 켜기\n",
    "    total_loss = 0.\n",
    "    log_interval = 200\n",
    "    start_time = time.time()\n",
    "\n",
    "    num_batches = len(train_data) // bptt\n",
    "    for batch, i in enumerate(range(0, train_data.size(0) - 1, bptt)):\n",
    "        data, targets = get_batch(train_data, i)\n",
    "        output = model(data)\n",
    "        output_flat = output.view(-1, ntokens)\n",
    "        loss = criterion(output_flat, targets)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        if batch % log_interval == 0 and batch > 0:\n",
    "            lr = scheduler.get_last_lr()[0]\n",
    "            ms_per_batch = (time.time() - start_time) * 1000 / log_interval\n",
    "            cur_loss = total_loss / log_interval\n",
    "            ppl = math.exp(cur_loss)\n",
    "            print(f'| epoch {epoch:3d} | {batch:5d}/{num_batches:5d} batches | '\n",
    "                  f'lr {lr:02.2f} | ms/batch {ms_per_batch:5.2f} | '\n",
    "                  f'loss {cur_loss:5.2f} | ppl {ppl:8.2f}')\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n",
    "\n",
    "def evaluate(model: nn.Module, eval_data: Tensor) -> float:\n",
    "    model.eval()  # 평가모드 켜기\n",
    "    total_loss = 0.\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, eval_data.size(0) - 1, bptt):\n",
    "            data, targets = get_batch(eval_data, i)\n",
    "            seq_len = data.size(0)\n",
    "            output = model(data)\n",
    "            output_flat = output.view(-1, ntokens)\n",
    "            total_loss += seq_len * criterion(output_flat, targets).item()\n",
    "    return total_loss / (len(eval_data) - 1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T18:42:52.438963400Z",
     "start_time": "2023-10-31T18:42:52.161683Z"
    }
   },
   "id": "be9e453638a9aca9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "* 주의! 아래코드를 실행하면 매우 많은 시간이 소모 됨"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b3f2b4868b42299d"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# best_val_loss = float('inf')\n",
    "# epochs = 3\n",
    "# \n",
    "# with TemporaryDirectory() as tempdir:\n",
    "#     best_model_params_path = os.path.join(tempdir, \"best_model_params.pt\")\n",
    "# \n",
    "#     for epoch in range(1, epochs + 1):\n",
    "#         epoch_start_time = time.time()\n",
    "#         train(model)\n",
    "#         val_loss = evaluate(model, val_data)\n",
    "#         val_ppl = math.exp(val_loss)\n",
    "#         elapsed = time.time() - epoch_start_time\n",
    "#         print('-' * 89)\n",
    "#         print(f'| end of epoch {epoch:3d} | time: {elapsed:5.2f}s | '\n",
    "#             f'valid loss {val_loss:5.2f} | valid ppl {val_ppl:8.2f}')\n",
    "#         print('-' * 89)\n",
    "# \n",
    "#         if val_loss < best_val_loss:\n",
    "#             best_val_loss = val_loss\n",
    "#             torch.save(model.state_dict(), best_model_params_path)\n",
    "# \n",
    "#         scheduler.step()\n",
    "#     model.load_state_dict(torch.load(best_model_params_path)) # 가장 좋은 모델 state 불러오기"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T18:43:19.216030700Z",
     "start_time": "2023-10-31T18:43:19.199687800Z"
    }
   },
   "id": "9561a24a44c64d4d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 테스트셋 데이터로 가장 좋은 모델을 평가하기"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ff04fcfd3d38978c"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss 10.67 | test ppl 42965.40\n",
      "=========================================================================================\n"
     ]
    }
   ],
   "source": [
    "test_loss = evaluate(model, test_data)\n",
    "test_ppl = math.exp(test_loss)\n",
    "print('=' * 89)\n",
    "print(f'| End of training | test loss {test_loss:5.2f} | '\n",
    "      f'test ppl {test_ppl:8.2f}')\n",
    "print('=' * 89)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T18:50:52.493466800Z",
     "start_time": "2023-10-31T18:50:23.689061500Z"
    }
   },
   "id": "1926821fa30cddd2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3d884fd740499c6e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
