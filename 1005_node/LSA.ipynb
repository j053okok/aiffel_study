{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-05T05:14:30.797775500Z",
     "start_time": "2023-10-05T05:14:30.033065600Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\008yo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\008yo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\008yo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nltk.download('punkt')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('stopwords')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-05T05:14:58.788853200Z",
     "start_time": "2023-10-05T05:14:57.914250600Z"
    }
   },
   "id": "b4da2985adf9ea83"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "(1082168, 2)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"abcnews-date-text.csv\")\n",
    "df.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-05T05:17:27.328572100Z",
     "start_time": "2023-10-05T05:17:26.730760700Z"
    }
   },
   "id": "376f92cde638d1ba"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "   publish_date                                      headline_text\n0      20030219  aba decides against community broadcasting lic...\n1      20030219     act fire witnesses must be aware of defamation\n2      20030219     a g calls for infrastructure protection summit\n3      20030219           air nz staff in aust strike for pay rise\n4      20030219      air nz strike to affect australian travellers",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>publish_date</th>\n      <th>headline_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>20030219</td>\n      <td>aba decides against community broadcasting lic...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20030219</td>\n      <td>act fire witnesses must be aware of defamation</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>20030219</td>\n      <td>a g calls for infrastructure protection summit</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>20030219</td>\n      <td>air nz staff in aust strike for pay rise</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>20030219</td>\n      <td>air nz strike to affect australian travellers</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-05T05:17:37.631814900Z",
     "start_time": "2023-10-05T05:17:37.614584600Z"
    }
   },
   "id": "bc7362c98d23ff60"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "                                       headline_text\n0  aba decides against community broadcasting lic...\n1     act fire witnesses must be aware of defamation\n2     a g calls for infrastructure protection summit\n3           air nz staff in aust strike for pay rise\n4      air nz strike to affect australian travellers",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>headline_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>aba decides against community broadcasting lic...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>act fire witnesses must be aware of defamation</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>a g calls for infrastructure protection summit</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>air nz staff in aust strike for pay rise</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>air nz strike to affect australian travellers</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = df[['headline_text']].copy()\n",
    "text.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-05T05:17:49.501810100Z",
     "start_time": "2023-10-05T05:17:49.458790500Z"
    }
   },
   "id": "633d12cfdf4c16ca"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "headline_text    1054983\ndtype: int64"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.nunique() # 중복을 제외하고 유일한 시퀀스를 가지는 샘플의 개수를 출력"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-05T05:18:26.196629500Z",
     "start_time": "2023-10-05T05:18:25.969111900Z"
    }
   },
   "id": "9528a387f10843da"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "(1054983, 1)"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.drop_duplicates(inplace=True) # 중복 샘플 제거\n",
    "text.reset_index(drop=True, inplace=True)\n",
    "text.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-05T05:18:37.416853Z",
     "start_time": "2023-10-05T05:18:37.281921800Z"
    }
   },
   "id": "82c0a74cd6bf7c38"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 데이터 정제 및 정규화\n",
    "* NLTK의 토크나이저를 이용해 전체 텍스트 데이터에 대해서 단어 토큰화를 수행\n",
    "* NLTK가 제공하는 불용어 리스트를 사용하여 불용어를 제거"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f1cb336e1922bc20"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "                                       headline_text\n0   [aba, decides, community, broadcasting, licence]\n1    [act, fire, witnesses, must, aware, defamation]\n2     [g, calls, infrastructure, protection, summit]\n3          [air, nz, staff, aust, strike, pay, rise]\n4  [air, nz, strike, affect, australian, travellers]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>headline_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[aba, decides, community, broadcasting, licence]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[act, fire, witnesses, must, aware, defamation]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[g, calls, infrastructure, protection, summit]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[air, nz, staff, aust, strike, pay, rise]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[air, nz, strike, affect, australian, travellers]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NLTK 토크나이저를 이용해서 토큰화\n",
    "text['headline_text'] = text.apply(lambda row: nltk.word_tokenize(row['headline_text']), axis=1)\n",
    "\n",
    "# 불용어 제거\n",
    "stop_words = stopwords.words('english')\n",
    "text['headline_text'] = text['headline_text'].apply(lambda x: [word for word in x if word not in (stop_words)])\n",
    "\n",
    "text.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-05T05:21:38.235442100Z",
     "start_time": "2023-10-05T05:20:39.755664600Z"
    }
   },
   "id": "8f5905e90633f9b2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "* 동일한 단어지만 다른표현을 가지는 단어들은 하나의 단어로 통합하는 단어 정규화 과정\n",
    "* 길이가 1~2인 단어를 제거"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2fd5700532fe2fa8"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     [aba, decide, community, broadcast, licence]\n",
      "1    [act, fire, witness, must, aware, defamation]\n",
      "2       [call, infrastructure, protection, summit]\n",
      "3            [air, staff, aust, strike, pay, rise]\n",
      "4    [air, strike, affect, australian, travellers]\n",
      "Name: headline_text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 단어 정규화. 3인칭 단수 표현 -> 1인칭 변환, 과거형 동사 -> 현재형 동사 등을 수행한다.\n",
    "text['headline_text'] = text['headline_text'].apply(lambda x: [WordNetLemmatizer().lemmatize(word, pos='v') for word in x])\n",
    "\n",
    "# 길이가 1 ~ 2인 단어는 제거.\n",
    "text = text['headline_text'].apply(lambda x: [word for word in x if len(word) > 2])\n",
    "print(text[:5])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-05T05:22:44.233557100Z",
     "start_time": "2023-10-05T05:22:26.701313800Z"
    }
   },
   "id": "4467f792699e1b82"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 역토큰화 및 DTM 생성\n",
    "* 토큰화 과정을 역으로 되돌리는 역토큰화 과정"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ef0fe3b692a715a7"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# 역토큰화 (토큰화 작업을 역으로 수행)\n",
    "detokenized_doc = []\n",
    "for i in range(len(text)):\n",
    "    t = ' '.join(text[i])\n",
    "    detokenized_doc.append(t)\n",
    "\n",
    "train_data = detokenized_doc"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-05T05:24:24.049311Z",
     "start_time": "2023-10-05T05:24:22.628307300Z"
    }
   },
   "id": "2423e4dcaddcbc36"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "['aba decide community broadcast licence',\n 'act fire witness must aware defamation',\n 'call infrastructure protection summit',\n 'air staff aust strike pay rise',\n 'air strike affect australian travellers']"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 전처리 최종물 확인\n",
    "train_data[:5]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-05T05:24:37.033069400Z",
     "start_time": "2023-10-05T05:24:37.020020900Z"
    }
   },
   "id": "339176ec280dae98"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# 상위 5000개의 단어만 사용\n",
    "c_vectorizer = CountVectorizer(stop_words='english', max_features = 5000)\n",
    "document_term_matrix = c_vectorizer.fit_transform(train_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-05T05:24:55.937698600Z",
     "start_time": "2023-10-05T05:24:51.707758800Z"
    }
   },
   "id": "f5694393289d31d6"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "행렬의 크기 : (1054983, 5000)\n"
     ]
    }
   ],
   "source": [
    "print('행렬의 크기 :',document_term_matrix.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-05T05:24:59.331150Z",
     "start_time": "2023-10-05T05:24:59.322525700Z"
    }
   },
   "id": "1a8ca12ed0f07916"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### scikit-learn TruncatedSVD 활용"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "891e871e4b1f9b58"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 0.01203015, -0.00371729,  0.01834612, ...,  0.00326195,\n         0.00342136,  0.00894811],\n       [ 0.0290546 , -0.01084706,  0.01819475, ...,  0.00153605,\n        -0.01239243, -0.00781251],\n       [ 0.0050321 , -0.00203204,  0.00977834, ..., -0.00235831,\n         0.00195627,  0.00150727],\n       ...,\n       [ 0.02972299,  0.0041781 ,  0.02509516, ...,  0.0319858 ,\n         0.00921418, -0.02023933],\n       [ 0.06183063, -0.00513236,  0.13610724, ...,  0.95695778,\n         0.74001662, -0.15627101],\n       [ 0.0713694 ,  0.02823953,  0.00097514, ...,  0.00630366,\n         0.0173362 ,  0.01154871]])"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "n_topics = 10\n",
    "lsa_model = TruncatedSVD(n_components = n_topics)\n",
    "lsa_model.fit_transform(document_term_matrix)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-05T05:25:35.881814300Z",
     "start_time": "2023-10-05T05:25:33.008971300Z"
    }
   },
   "id": "a6744a3c4107488f"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 5000)\n"
     ]
    }
   ],
   "source": [
    "print(lsa_model.components_.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-05T05:25:56.190782Z",
     "start_time": "2023-10-05T05:25:56.182776800Z"
    }
   },
   "id": "2312a88bd8402019"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: [('police', 0.74637), ('man', 0.45358), ('charge', 0.21091), ('new', 0.14091), ('court', 0.11134)]\n",
      "Topic 2: [('man', 0.69434), ('charge', 0.30044), ('court', 0.16815), ('face', 0.1139), ('murder', 0.10635)]\n",
      "Topic 3: [('new', 0.8365), ('plan', 0.23647), ('say', 0.18248), ('council', 0.11034), ('govt', 0.10974)]\n",
      "Topic 4: [('say', 0.73847), ('plan', 0.35842), ('govt', 0.16857), ('council', 0.12749), ('urge', 0.07491)]\n",
      "Topic 5: [('plan', 0.73121), ('council', 0.1763), ('govt', 0.14209), ('urge', 0.08408), ('water', 0.07652)]\n",
      "Topic 6: [('govt', 0.50939), ('court', 0.27096), ('urge', 0.25224), ('fund', 0.22815), ('face', 0.16761)]\n",
      "Topic 7: [('charge', 0.51894), ('court', 0.44928), ('face', 0.34175), ('plan', 0.12773), ('murder', 0.12518)]\n",
      "Topic 8: [('win', 0.67142), ('court', 0.32503), ('crash', 0.1203), ('kill', 0.09795), ('face', 0.0947)]\n",
      "Topic 9: [('win', 0.53942), ('charge', 0.49807), ('council', 0.21431), ('sydney', 0.07153), ('cup', 0.06658)]\n",
      "Topic 10: [('council', 0.76832), ('man', 0.13958), ('change', 0.08022), ('court', 0.07392), ('water', 0.05091)]\n"
     ]
    }
   ],
   "source": [
    "terms = c_vectorizer.get_feature_names_out() # 단어 집합. 5,000개의 단어가 저장됨.\n",
    "\n",
    "def get_topics(components, feature_names, n=5):\n",
    "    for idx, topic in enumerate(components):\n",
    "        print(\"Topic %d:\" % (idx+1), [(feature_names[i], topic[i].round(5)) for i in topic.argsort()[:-n - 1:-1]])\n",
    "get_topics(lsa_model.components_, terms)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-05T05:26:00.267081300Z",
     "start_time": "2023-10-05T05:26:00.247145700Z"
    }
   },
   "id": "30770fc54a27b53c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7eaf8a71dc39be43"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
